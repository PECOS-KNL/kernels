
\section{Summary}
\label{sec:summary}

%
% achtung! old writing here
%
Overall, porting a number of different scientific applications and
kernels to the KNL architecture was relatively\todo{update this too!}
straightforward. Successfully ported applications (written in either
Fortran or C++) include serial codes as well as codes with existing
OpenMP- or TBB-based threading.  Even native compilation of 3rd-party
libraries was reasonably straightforward, with only a few
configuration options left unsupported and dynamic library builds not
successful across all of the libraries considered.
%uniformly supported.

Performance results vary more widely.\todo{add mention of code on
github?}  We have demonstrated good 
strong scaling to large thread counts for some of our computational
kernels, but others only effectively used a fraction of the MIC's
potential capability.  However, runtime performance improved 
for large thread counts on all workloads, and simple changes to
thread algorithms or affinity settings often delivered further
improvements.  Different workloads require different settings in order
to achieve peak performance. Finally, vectorization is important in
order to fully exploit the MIC architecture. When comparing FFT
results obtained with MKL and FFTW, the improved vectorization in
MKL accounts for better performance and scalability.

