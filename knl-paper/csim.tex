\subsection{EOM-CCSDT single-node performance}
\label{sec:cfour}

For the calculations used in this work,
the CFOUR \cite{cfour:08} program was used. CFOUR
(Coupled-Cluster techniques for Computational Chemistry) is an
application for performing high-level quantum chemical calculations
that is under active development by research groups at UT Austin and
Universit\"{a}t Mainz, Germany. CFOUR's major strength is its arsenal
of high-level {\emph ab initio} methods for the calculation of atomic and
molecular properties.  Virtually all approaches based on M\o
ller-Plesset (MP) perturbation theory and the coupled-cluster
approximation (CC) are available.

For the other applications considered here, the scalibility of various code bases 
used in the PECOS center on KNL compute nodes has been presented. To compliment
this effort, this section will focus on a comparison of optimal single-node performance
between traditional (Haswell) Intel CPUs and the new KNL compute nodes of Stampede 2.
While the scalability of CFOUR on current and emerging architectures will be the focus 
of future work, the results presented here will detail overall runtime performance gains
from migrating to this new architecture. 

For this work, the performance of a single calculation, the EOM-CCSDT energy of the first
excited singlet state of $C_2H_2$, was studied in detail. This excited state is the focus
of a current study being conducted by authors of this paper in which over 1 million single point
energies on a potential energy surface will be calculated. As such, ensuring the best performance for this run 
type will conserve important national compute resources available at TACC. All EOM-CCSDT calculations were performed 
using the NCC module \cite{ncc:15} of the CFOUR program system and the ANO1 basis set \cite{ano1:87} with core 
electrons uncorrelated. A nonequilibrium geometry of this excited singlet state was used that has C1 symmetry. 
The lowest symmetry point group available to $C_2H_2$ was used because this computational requires the most memory 
and compute time. This establishes an upper bound per computation.

Porting CFOUR to the KNL architecture was very straightforward. No modification of the code or the build
system was required. All that needed to be done was to add the previously discussed compile and link flags
to the corresponding Fortran, C, and C++ environmental variables.

The NCC module in CFOUR is a recent contribution to the code and, as such, has been designed to take
advantage of many-core architectures. It uses OpenMP for thread-based parallelism and in this work, the
built-in parallelism of Intel's MKL is also exploited. As has been discussed in detail previously \cite{ncc:15},
it has been determined that on traditional dual Intel CPU compute node systems, best performance is obtained 
by using $OMP\_NUM\_THREADS=16$. This relies on the default behavior that MKL will use $OMP\_NUM\_THREADS$ 
if outside an OpenMP block but run single-threaded within an OpenMP block. In the NCC module, there are MKL-library 
calls within an OpenMP block, however, best performance is achieved by using only serial MKL calls within OpenMP
blocks. This ensures that thread oversubscription never occurs.

For benchmark comparison purposes, the traditional CPU used for reference was an Intel Xeon  E5-2670 v3 CPU
running at 2.30GHz. This CPU was first available on market in late 2014 and is representative of typical HPC 
compute nodes in current generation supercomputers. Best performance on this system was achieved with 
$OMP\_NUM\_THREADS=16$ and the total compute time for the $C_2H_2$ excited state energy discussed previously
was 607s. If more than 16 threads were used, the total walltime for the calculation increases. Additionally,
a single-core job took 3514s.

While the KNL architecture offers three different memory modes, only two of those are supported on Stampede 2,
cache mode and flat mode. Cache mode preallocates all of the ``fast'' MCDRAM as direct-mapped L3 cache and
as such only the 96 GB DDR4 RAM is presented to the operating system. Flat mode presents both the MCDRAM and the 
DDR RAM to the operating system and the user can use the ``numactl'' utility to decide at run time if memory 
allocations should be directed to the 16 GB of MCDRAM or the 96 GB of DDR RAM. For these comparisons, Intel's 
recommended default cluster mode of ``Quadrant'' is used. 

This mode attempts to localize communication without requiring explicit memory management by the user. 
It does this by grouping tiles into four logical/virtual (not physical) quadrants, then requiring each tile 
to manage MCDRAM addresses only in its own quadrant (and DDR addresses in its own half of the chip). 
This reduces the average number of ``hops'' that tile-to-memory requests require compared to all-to-all mode, 
which can reduce latency and congestion on the mesh.  This results in three different runtime configurations: 
flat mode with DDR RAM in Qudrant mode (5284s), flat mode with MCDRAM in Quadrant mode(xxxx s), and 
Cache-Quadrant mode (5467s).
\subsubsection{cluster mode}
\subsubsection{threads and mkl and environmental variables oh my}
\subsubsection{cfour conclusion}
